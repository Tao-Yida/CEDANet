import torch
import torch.nn.functional as F
import warnings
from torch import no_grad

import numpy as np
import os, argparse
from datetime import datetime
from torch.optim import lr_scheduler
from model.ResNet_models import Generator, Descriptor
from dataloader import get_train_val_loaders, get_dataset_name_from_path
from utils import adjust_lr, AvgMeter, EarlyStopping, validate_model, generate_model_name, generate_checkpoint_filename, generate_best_model_filename
from scipy import misc
import cv2
import torchvision.transforms as transforms
from utils import l2_regularisation
import smoothness
from lscloss import *

# Define computation device (GPU/CPU)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

parser = argparse.ArgumentParser()
parser.add_argument("--epoch", type=int, default=50, help="epoch number")  # è®­ç»ƒè½®æ•°
parser.add_argument("--lr_gen", type=float, default=2.5e-5, help="learning rate for generator")  # ç”Ÿæˆå™¨å­¦ä¹ ç‡
parser.add_argument("--lr_des", type=float, default=2.5e-5, help="learning rate for descriptor")  # æè¿°å™¨å­¦ä¹ ç‡
parser.add_argument("--batchsize", type=int, default=7, help="number of samples per batch")  # æ‰¹é‡å¤§å°
parser.add_argument(
    "--trainsize", type=int, default=352, help="input image resolution (trainsize x trainsize)"
)  # è¾“å…¥å›¾åƒåˆ†è¾¨ç‡ï¼Œè®­ç»ƒæ—¶çš„å›¾åƒå¤§å°ï¼Œåˆ«éšä¾¿è°ƒï¼ï¼
parser.add_argument("--clip", type=float, default=0.5, help="gradient clipping margin")  # æ¢¯åº¦è£å‰ªè¾¹é™…ï¼Œç”¨äºé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸
parser.add_argument("--decay_rate", type=float, default=0.9, help="decay rate of learning rate")  # å­¦ä¹ ç‡è¡°å‡ç‡ï¼Œç”¨äºè°ƒæ•´å­¦ä¹ ç‡
parser.add_argument("--decay_epoch", type=int, default=20, help="every n epochs decay learning rate")  # å­¦ä¹ ç‡è¡°å‡å‘¨æœŸ
parser.add_argument("--beta", type=float, default=0.5, help="beta of Adam for generator")  # Adamä¼˜åŒ–å™¨çš„betaå‚æ•°
parser.add_argument("--gen_reduced_channel", type=int, default=32, help="reduced channel in generator")  # ç”Ÿæˆå™¨ä¸­å‡å°‘çš„é€šé“æ•°
parser.add_argument("--des_reduced_channel", type=int, default=64, help="reduced channel in descriptor")  # æè¿°å™¨ä¸­å‡å°‘çš„é€šé“æ•°
parser.add_argument(
    "--langevin_step_num_des", type=int, default=10, help="number of langevin steps for ebm"
)  # EBMçš„langevinæ­¥éª¤æ•°ï¼ŒEBMæ˜¯èƒ½é‡åŸºæ¨¡å‹ï¼Œlangevinæ­¥éª¤æ˜¯æŒ‡åœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­ä½¿ç”¨çš„è¿­ä»£æ­¥éª¤æ•°
parser.add_argument("-langevin_step_size_des", type=float, default=0.026, help="step size of EBM langevin")  # EBM langevinçš„æ­¥é•¿
parser.add_argument(
    "--energy_form", default="identity", help="tanh | sigmoid | identity | softplus"
)  # èƒ½é‡å‡½æ•°çš„å½¢å¼ï¼Œtanhï¼šåŒæ›²æ­£åˆ‡å‡½æ•°ï¼Œsigmoidï¼šSå‹å‡½æ•°ï¼Œidentityï¼šæ’ç­‰å‡½æ•°ï¼Œsoftplusï¼šå¹³æ»‘çš„ReLUå‡½æ•°
parser.add_argument("--latent_dim", type=int, default=3, help="latent dim")  # æ½œåœ¨ç»´åº¦ï¼Œç”¨äºç”Ÿæˆå™¨å’Œæè¿°å™¨çš„æ½œåœ¨ç©ºé—´
parser.add_argument("--feat_channel", type=int, default=32, help="reduced channel of saliency feat")  # é‡è¦æ€§ç‰¹å¾çš„é€šé“æ•°
parser.add_argument("--sm_weight", type=float, default=0.1, help="weight for smoothness loss")  # å¹³æ»‘æ€§æŸå¤±çš„æƒé‡
parser.add_argument("--reg_weight", type=float, default=1e-4, help="weight for regularization term")  # æ­£åˆ™åŒ–é¡¹çš„æƒé‡
parser.add_argument("--lat_weight", type=float, default=10.0, help="weight for latent loss")  # æ½œåœ¨æŸå¤±çš„æƒé‡
parser.add_argument("--vae_loss_weight", type=float, default=0.4, help="weight for vae loss")  # VAEæŸå¤±çš„æƒé‡ï¼ŒVAEæ˜¯å˜åˆ†è‡ªç¼–ç å™¨ï¼Œç”¨äºç”Ÿæˆæ¨¡å‹
parser.add_argument("--dataset_path", type=str, default="data/ijmond_data/train", help="dataset path")  # è®­ç»ƒæ•°æ®é›†è·¯å¾„
parser.add_argument("--pretrained_weights", type=str, default=None, help="pretrained weights. it can be none")  # é¢„è®­ç»ƒæƒé‡è·¯å¾„ï¼Œå¯ä»¥ä¸ºNone
parser.add_argument("--save_model_path", type=str, default="models/full-supervision", help="dataset path")  # æ¨¡å‹ä¿å­˜è·¯å¾„
# æ ¡éªŒç›¸å…³å‚æ•°
parser.add_argument("--val_split", type=float, default=0.2, help="fraction of dataset used for validation (0.0-1.0)")
parser.add_argument("--patience", type=int, default=15, help="early stopping patience")  # æ—©åœè€å¿ƒå€¼
parser.add_argument("--min_delta", type=float, default=0.001, help="minimum improvement for early stopping")  # æ—©åœæœ€å°æ”¹å–„å€¼

# æ‰€æœ‰è¶…å‚æ•°ä¿å­˜åœ¨optä¸­
opt = parser.parse_args()

# è·å–æ•°æ®é›†åç§°å¹¶ç”Ÿæˆæ¨¡å‹åç§°
dataset_name = get_dataset_name_from_path(opt.dataset_path)
model_name = generate_model_name(dataset_name, opt.pretrained_weights)
original_save_path = opt.save_model_path
opt.save_model_path = os.path.join(original_save_path, model_name)

print("\n========== Training Configuration ==========")
print("Training Epochs: {}".format(opt.epoch))
print("Learning Rates:")
print("  - Generator: {}".format(opt.lr_gen))
print("  - Descriptor: {}".format(opt.lr_des))
print("\nOptimization Settings:")
print("  - Batch Size: {}".format(opt.batchsize))
print("  - Training Size: {}".format(opt.trainsize))
print("  - Gradient Clip: {}".format(opt.clip))
print("  - Adam Beta: {}".format(opt.beta))
print("\nLearning Rate Schedule:")
print("  - Decay Rate: {}".format(opt.decay_rate))
print("  - Decay Epoch: {}".format(opt.decay_epoch))
print("\nModel Architecture:")
print("  - Generator Reduced Channel: {}".format(opt.gen_reduced_channel))
print("  - Descriptor Reduced Channel: {}".format(opt.des_reduced_channel))
print("  - Feature Channel: {}".format(opt.feat_channel))
print("  - Latent Dimension: {}".format(opt.latent_dim))
print("\nLoss Weights:")
print("  - Smoothness Weight: {}".format(opt.sm_weight))
print("  - Regularization Weight: {}".format(opt.reg_weight))
print("  - Latent Loss Weight: {}".format(opt.lat_weight))
print("  - VAE Loss Weight: {}".format(opt.vae_loss_weight))
print("\nPaths:")
print("  - Dataset Path: {}".format(opt.dataset_path))
print("  - Dataset Name: {}".format(dataset_name))
print("  - Model Name: {}".format(model_name))
print("  - Original Save Path: {}".format(original_save_path))
print("  - Final Save Path: {}".format(opt.save_model_path))
print("  - Pretrained Weights: {}".format(opt.pretrained_weights))
print("\nValidation Settings:")
print("  - Validation Split: {}".format(opt.val_split))
print("  - Early Stopping Patience: {}".format(opt.patience))
print("  - Min Delta: {}".format(opt.min_delta))
print("\nEBM Settings:")
print("  - Langevin Steps: {}".format(opt.langevin_step_num_des))
print("  - Langevin Step Size: {}".format(opt.langevin_step_size_des))
print("  - Energy Form: {}".format(opt.energy_form))
print("==========================================\n")

# build models
generator = Generator(channel=opt.feat_channel, latent_dim=opt.latent_dim)  # ç”Ÿæˆå™¨æ¨¡å‹

# å¦‚æœæœ‰é¢„è®­ç»ƒæƒé‡ï¼Œåˆ™åŠ è½½é¢„è®­ç»ƒæƒé‡ï¼Œå¦åˆ™ä½¿ç”¨éšæœºåˆå§‹åŒ–
if opt.pretrained_weights is not None:
    print(f"Load pretrained weights: {opt.pretrained_weights}")
    generator.load_state_dict(torch.load(opt.pretrained_weights))

generator.to(device)  # å°†ç”Ÿæˆå™¨æ¨¡å‹ç§»åŠ¨åˆ°è®¡ç®—è®¾å¤‡ä¸Š
generator_params = generator.parameters()  # è·å–ç”Ÿæˆå™¨æ¨¡å‹çš„å‚æ•°ï¼Œæ ¼å¼ä¸ºå¯è¿­ä»£å¯¹è±¡
generator_optimizer = torch.optim.Adam(
    generator_params, lr=opt.lr_gen, betas=(opt.beta, 0.999)
)  # Adamä¼˜åŒ–å™¨ï¼Œbetasçš„ä½œç”¨æ˜¯æ§åˆ¶ä¸€é˜¶çŸ©ä¼°è®¡å’ŒäºŒé˜¶çŸ©ä¼°è®¡çš„è¡°å‡ç‡

image_root = os.path.join(opt.dataset_path, "img/")  # data/ijmond_data/test/img
gt_root = os.path.join(opt.dataset_path, "gt/")  # data/ijmond_data/test/gt
trans_map_root = os.path.join(opt.dataset_path, "trans/")  # data/ijmond_data/test/trans

# è·å–æ•°æ®åŠ è½½å™¨ - ä¿®æ”¹ä¸ºä½¿ç”¨è®­ç»ƒ/æ ¡éªŒåˆ†å‰²
train_loader, val_loader = get_train_val_loaders(
    image_root, gt_root, trans_map_root, batchsize=opt.batchsize, trainsize=opt.trainsize, val_split=opt.val_split, random_seed=42
)
# è®¡ç®—æ•°æ®é›†çš„æ€»æ­¥æ•°ï¼Œè®­ç»ƒé›†è¢«åˆ†æˆå¤šä¸ªbatchè¿›è¡Œè®­ç»ƒ
total_step = len(train_loader)
print(f"Training steps per epoch: {total_step}")
print(f"Validation steps per epoch: {len(val_loader)}")

# åˆå§‹åŒ–æ—©åœç­–ç•¥å’Œæœ€ä½³æ¨¡å‹è·Ÿè¸ª
early_stopping = EarlyStopping(patience=opt.patience, min_delta=opt.min_delta, restore_best_weights=True)
best_val_iou = 0.0
best_epoch = 0

scheduler = lr_scheduler.StepLR(generator_optimizer, step_size=10, gamma=0.5)
bce_loss = torch.nn.BCELoss()
mse_loss = torch.nn.MSELoss(reduction="mean")  # æ–°ç‰ˆPyTorchä½¿ç”¨reductionå‚æ•°
size_rates = [1]  # multi-scale trainingï¼Œå°ºåº¦å› å­ï¼Œè¿™é‡Œè®¾ç½®ä¸º1è¡¨ç¤ºä¸è¿›è¡Œç¼©æ”¾
smooth_loss = smoothness.smoothness_loss(size_average=True)  # å¹³æ»‘æ€§æŸå¤±å‡½æ•°ï¼Œçº¦æŸç”Ÿæˆçš„å›¾åƒå¹³æ»‘æ€§
lsc_loss = LocalSaliencyCoherence().to(device)  # å±€éƒ¨æ˜¾è‘—æ€§ä¸€è‡´æ€§æŸå¤±å‡½æ•°ï¼Œåœ¨ç»†ç²’åº¦åŒºåŸŸåŠ å¼ºé¢„æµ‹çš„ä¸€è‡´æ€§
lsc_loss_kernels_desc_defaults = [{"weight": 0.1, "xy": 3, "trans": 0.1}]  # ç”¨äºè®¡ç®—æ ¸å‡½æ•°
lsc_loss_radius = 2  # é‚»åŸŸåŠå¾„
weight_lsc = 0.01  # æ§åˆ¶å±€éƒ¨æ˜¾è‘—æ€§ä¸€è‡´æ€§æŸå¤±åœ¨æ€»æŸå¤±ä¸­çš„æƒé‡


def structure_loss(pred, mask):
    """
    ç»“æ„æŸå¤±ï¼Œç”¨äºè¯„ä¼°é¢„æµ‹çš„æ˜¾è‘—æ€§å›¾ä¸çœŸå®æ˜¾è‘—æ€§å›¾ä¹‹é—´çš„å·®å¼‚
    é€šè¿‡è®¡ç®—åŠ æƒçš„äºŒè¿›åˆ¶äº¤å‰ç†µæŸå¤±å’ŒåŠ æƒçš„IoUæŸå¤±æ¥å®ç°
    Args:
        pred: predicted saliency map
        mask: ground truth saliency map
    Returns:
        loss: structure loss
    Formula:
        IoU = (pred * mask) / (pred + mask - pred * mask)
        loss = (BCE(pred, mask) + (1 - IoU)) / 2
    """
    weight = 1 + 5 * torch.abs(
        F.avg_pool2d(mask, kernel_size=31, stride=1, padding=15) - mask
    )  # è®¡ç®—åŠ æƒå› å­ï¼Œåœ¨maskä¸å…¶å±€éƒ¨å‡å€¼ä¹‹é—´çš„å·®å¼‚è¶Šå¤§ï¼Œæƒé‡è¶Šå¤§ï¼Œä»è€Œæ›´å…³æ³¨è¾¹ç¼˜æˆ–è¿‡æ¸¡åŒºåŸŸ
    weighted_bce_loss = F.binary_cross_entropy_with_logits(pred, mask, reduction="none")
    weighted_bce_loss = (weight * weighted_bce_loss).sum(dim=(2, 3)) / weight.sum(dim=(2, 3))  # dim=(2, 3)è¡¨ç¤ºåœ¨ç©ºé—´ç»´åº¦ä¸Šè¿›è¡Œæ±‚å’Œï¼Œå¯¹åº”é«˜åº¦å’Œå®½åº¦

    pred = torch.sigmoid(pred)
    inter = ((pred * mask) * weight).sum(dim=(2, 3))  # äº¤é›†ï¼Œåªæœ‰åœ¨å¯¹åº”åƒç´ å¤„ä¸¤è€…éƒ½è¾ƒé«˜æ—¶ï¼ˆå³éƒ½æœ‰è¾ƒé«˜ç½®ä¿¡åº¦ï¼‰ä¹˜ç§¯æ‰å¤§ï¼Œåæ˜ äº†å…±åŒæ¿€æ´»åŒºåŸŸçš„å¼ºåº¦
    union = (((pred + mask - pred * mask)) * weight).sum(dim=(2, 3))  # è¡¨ç¤ºé¢„æµ‹å’ŒçœŸå®å„è‡ªçš„è´¡çŒ®
    weighted_IoU = (inter + 1e-6) / (union + 1e-6)  # åŠ 1e-6é˜²æ­¢é™¤0é”™è¯¯
    weighted_IoU_loss = 1 - weighted_IoU  # IoUæŸå¤±ï¼ŒIoUè¶Šé«˜ï¼ŒæŸå¤±è¶Šä½
    return (weighted_bce_loss + weighted_IoU_loss).mean()


def visualize_prediction_init(pred):
    """
    å¯è§†åŒ–é¢„æµ‹ç»“æœ
    Args:
        pred: Predicted saliency map, size: [batch_size, channels, height, width]
    """
    # éå†æ¯ä¸ªbatchä¸­çš„å›¾åƒ
    for kk in range(pred.shape[0]):
        pred_edge_kk = pred[kk, :, :, :]  # æå–ç¬¬kkä¸ªå›¾åƒçš„é¢„æµ‹ç»“æœ
        pred_edge_kk = pred_edge_kk.detach().cpu().numpy().squeeze()
        pred_edge_kk *= 255.0  # å°†é¢„æµ‹ç»“æœç¼©æ”¾åˆ°0-255èŒƒå›´
        pred_edge_kk = pred_edge_kk.astype(np.uint8)  # è½¬æ¢ä¸ºuint8ç±»å‹
        save_path = "./temp/"
        name = "{:02d}_init.png".format(kk)
        misc.imsave(save_path + name, pred_edge_kk)


def visualize_prediction_ref(pred):

    for kk in range(pred.shape[0]):
        pred_edge_kk = pred[kk, :, :, :]
        pred_edge_kk = pred_edge_kk.detach().cpu().numpy().squeeze()
        pred_edge_kk *= 255.0
        pred_edge_kk = pred_edge_kk.astype(np.uint8)
        save_path = "./temp/"
        name = "{:02d}_ref.png".format(kk)
        misc.imsave(save_path + name, pred_edge_kk)


def visualize_gt(var_map):

    for kk in range(var_map.shape[0]):
        pred_edge_kk = var_map[kk, :, :, :]
        pred_edge_kk = pred_edge_kk.detach().cpu().numpy().squeeze()
        pred_edge_kk *= 255.0
        pred_edge_kk = pred_edge_kk.astype(np.uint8)
        save_path = "./temp/"
        name = "{:02d}_gt.png".format(kk)
        misc.imsave(save_path + name, pred_edge_kk)


def visualize_original_img(rec_img):
    img_transform = transforms.Compose(
        [transforms.Normalize(mean=[-0.4850 / 0.229, -0.456 / 0.224, -0.406 / 0.225], std=[1 / 0.229, 1 / 0.224, 1 / 0.225])]
    )
    for kk in range(rec_img.shape[0]):
        current_img = rec_img[kk, :, :, :]
        current_img = img_transform(current_img)
        current_img = current_img.detach().cpu().numpy().squeeze()
        current_img = current_img * 255
        current_img = current_img.astype(np.uint8)
        save_path = "./temp/"
        name = "{:02d}_img.png".format(kk)
        current_img = current_img.transpose((1, 2, 0))
        current_b = current_img[:, :, 0]
        current_b = np.expand_dims(current_b, 2)
        current_g = current_img[:, :, 1]
        current_g = np.expand_dims(current_g, 2)
        current_r = current_img[:, :, 2]
        current_r = np.expand_dims(current_r, 2)
        new_img = np.concatenate((current_r, current_g, current_b), axis=2)
        cv2.imwrite(save_path + name, new_img)


## linear annealing to avoid posterior collapse
def linear_annealing(init, fin, step, annealing_steps):
    """
    Linear annealing of a parameter.
    Args:
        init: initial value
        fin: final value
        step: current step
        annealing_steps: total steps for annealing
    """
    if annealing_steps == 0:  # å¦‚æœæ²¡æœ‰è®¾ç½®é€€ç«æ­¥æ•°ï¼Œåˆ™ç›´æ¥è¿”å›æœ€ç»ˆå€¼
        return fin
    assert fin > init
    delta = fin - init
    annealed = min(init + delta * step / annealing_steps, fin)
    return annealed


print("Let's go!")
# åœ¨è®­ç»ƒå¼€å§‹å‰ç¡®ä¿ä¿å­˜ç›®å½•å­˜åœ¨
save_path = opt.save_model_path
if not os.path.exists(save_path):
    os.makedirs(save_path)
    print(f"Created save directory: {save_path}")

for epoch in range(1, (opt.epoch + 1)):
    print("--" * 10 + "Epoch: {}/{}".format(epoch, opt.epoch) + "--" * 10)
    # ç§»é™¤æ­¤å¤„çš„scheduler.step()ï¼Œå°†åœ¨epochç»“æŸåè°ƒç”¨
    generator.train()
    loss_record = AvgMeter()

    # è®­ç»ƒé˜¶æ®µ
    for i, pack in enumerate(train_loader, start=1):
        for rate in size_rates:
            generator_optimizer.zero_grad()
            images, gts, trans = pack
            # ä½¿ç”¨è®¾å¤‡æ— å…³çš„.to(device)æ›¿ä»£.cuda()
            images = images.to(device)
            gts = gts.to(device)
            trans = trans.to(device)
            # multi-scale training samples
            trainsize = int(round(opt.trainsize * rate / 32) * 32)  # å°†è®­ç»ƒå¤§å°è°ƒæ•´ä¸º32çš„å€æ•°ï¼Œå…¼å®¹å¤§å¤šæ•°ç½‘ç»œï¼ˆä¸Šä¸‹é‡‡æ ·æ“ä½œéœ€è¦è¾“å…¥å°ºå¯¸ä¸º32çš„å€æ•°ï¼‰
            if rate != 1:  # å¦‚æœä¸æ˜¯åŸå§‹å¤§å°ï¼Œåˆ™è¿›è¡Œä¸Šé‡‡æ ·
                images = F.interpolate(images, size=(trainsize, trainsize), mode="bilinear", align_corners=True)
                gts = F.interpolate(gts, size=(trainsize, trainsize), mode="bilinear", align_corners=True)
                trans = F.interpolate(trans, size=(trainsize, trainsize), mode="bilinear", align_corners=True)

            pred_post_init, pred_post_ref, pred_prior_init, pred_piror_ref, latent_loss = generator.forward(images, gts)

            # re-scale data for crf loss
            # ä¸‹é‡‡æ ·è‡³åŸæ¥çš„0.3å€ï¼Œæ–¹ä¾¿è®¡ç®—CRFæŸå¤±ï¼Œæå‡è®¡ç®—é€Ÿåº¦
            trans_scale = F.interpolate(trans, scale_factor=0.3, mode="bilinear", align_corners=True)
            images_scale = F.interpolate(images, scale_factor=0.3, mode="bilinear", align_corners=True)
            pred_prior_init_scale = F.interpolate(pred_prior_init, scale_factor=0.3, mode="bilinear", align_corners=True)
            pred_prior_ref_scale = F.interpolate(pred_post_ref, scale_factor=0.3, mode="bilinear", align_corners=True)
            pred_post_init_scale = F.interpolate(pred_post_init, scale_factor=0.3, mode="bilinear", align_corners=True)
            pred_post_ref_scale = F.interpolate(pred_post_ref, scale_factor=0.3, mode="bilinear", align_corners=True)
            sample = {"trans": trans_scale}

            loss_lsc_1 = lsc_loss(
                torch.sigmoid(pred_post_init_scale),
                lsc_loss_kernels_desc_defaults,
                lsc_loss_radius,
                sample,
                trans_scale.shape[2],
                trans_scale.shape[3],
            )["loss"]
            loss_lsc_2 = lsc_loss(
                torch.sigmoid(pred_post_ref_scale),
                lsc_loss_kernels_desc_defaults,
                lsc_loss_radius,
                sample,
                trans_scale.shape[2],
                trans_scale.shape[3],
            )["loss"]
            loss_lsc_post = weight_lsc * (loss_lsc_1 + loss_lsc_2)

            ## l2 regularizer the inference model
            reg_loss = l2_regularisation(generator.xy_encoder) + l2_regularisation(generator.x_encoder) + l2_regularisation(generator.sal_encoder)
            # smoothLoss_post = opt.sm_weight * smooth_loss(torch.sigmoid(pred_post), grays)
            reg_loss = opt.reg_weight * reg_loss  # å¯¹æ­£åˆ™åŒ–æŸå¤±è¿›è¡ŒåŠ æƒï¼Œæ§åˆ¶æ­£åˆ™åŒ–æŸå¤±åœ¨æ€»æŸå¤±ä¸­çš„æƒé‡
            latent_loss = latent_loss

            sal_loss = 0.5 * (
                structure_loss(pred_post_init, gts) + structure_loss(pred_post_ref, gts)
            )  # ä¸¤ä¸ªé¢„æµ‹åéªŒç»“æœçš„ç»“æ„æŸå¤±ï¼Œè¡¡é‡é¢„æµ‹ç»“æœä¸çœŸå®æ ‡ç­¾ä¹‹é—´çš„å·®å¼‚ï¼Œå…¼é¡¾åƒç´ çº§å’ŒåŒºåŸŸçº§çš„å‡†ç¡®æ€§
            anneal_reg = linear_annealing(
                0, 1, epoch, opt.epoch
            )  # é˜²æ­¢è®­ç»ƒåˆæœŸæ½œåœ¨ç©ºé—´å´©å¡Œï¼ˆposterior collapseï¼‰ï¼Œè®©æ¨¡å‹å…ˆå…³æ³¨é‡å»ºï¼Œå†é€æ­¥åŠ å¼ºå¯¹æ½œåœ¨åˆ†å¸ƒçš„çº¦æŸ
            latent_loss = opt.lat_weight * anneal_reg * latent_loss

            loss_lsc_3 = lsc_loss(
                torch.sigmoid(pred_prior_init_scale),
                lsc_loss_kernels_desc_defaults,
                lsc_loss_radius,
                sample,
                trans_scale.shape[2],
                trans_scale.shape[3],
            )["loss"]
            loss_lsc_4 = lsc_loss(
                torch.sigmoid(pred_prior_ref_scale),
                lsc_loss_kernels_desc_defaults,
                lsc_loss_radius,
                sample,
                trans_scale.shape[2],
                trans_scale.shape[3],
            )["loss"]
            loss_lsc_prior = weight_lsc * (loss_lsc_3 + loss_lsc_4)

            # æ¡ä»¶è‡ªåˆ†è‡ªç¼–ç å™¨æŸå¤±ï¼ŒåŒ…æ‹¬æ˜¾è‘—æ€§å·®å¼‚æŸå¤±ã€æ½œåœ¨ç©ºé—´æŸå¤±å’ŒåéªŒä¸€è‡´æ€§æŸå¤±
            gen_loss_cvae = sal_loss + latent_loss + loss_lsc_post
            gen_loss_cvae = opt.vae_loss_weight * gen_loss_cvae

            # ç”Ÿæˆå™¨çš„ç»“æ„æŸå¤±
            gen_loss_gsnn = 0.5 * (structure_loss(pred_prior_init, gts) + structure_loss(pred_post_ref, gts))
            gen_loss_gsnn = (1 - opt.vae_loss_weight) * gen_loss_gsnn + loss_lsc_prior
            # total loss
            gen_loss = gen_loss_cvae + gen_loss_gsnn + reg_loss
            gen_loss.backward()
            generator_optimizer.step()

            if rate == 1:
                loss_record.update(gen_loss.data, opt.batchsize)

        if i % 10 == 0 or i == total_step:
            # è®¡ç®—åƒç´ çº§æ··æ·†çŸ©é˜µæŒ‡æ ‡
            with torch.no_grad():
                # äºŒå€¼åŒ–é¢„æµ‹ï¼Œé˜ˆå€¼0.5
                pred_bin = (torch.sigmoid(pred_post_init) > 0.5).float()
                gt_bin = gts
                # å±•å¹³æ‰€æœ‰åƒç´ 
                pred_flat = pred_bin.view(-1)
                gt_flat = gt_bin.view(-1)
                tp = ((pred_flat == 1) & (gt_flat == 1)).sum().item()
                tn = ((pred_flat == 0) & (gt_flat == 0)).sum().item()
                fp = ((pred_flat == 1) & (gt_flat == 0)).sum().item()
                fn = ((pred_flat == 0) & (gt_flat == 1)).sum().item()
            # æ‰“å°æ€»æŸå¤±åŠæ··æ·†çŸ©é˜µ
            print(
                "{} Epoch [{:03d}/{:03d}], Step [{:04d}/{:04d}], Gen Loss: {:.4f}, TP: {}, FP: {}, TN: {}, FN: {}".format(
                    datetime.now(), epoch, opt.epoch, i, total_step, loss_record.show(), tp, fp, tn, fn
                )
            )

    # åœ¨è®­ç»ƒå¾ªç¯ç»“æŸåè°ƒç”¨scheduler.step()
    scheduler.step()
    current_lr = scheduler.get_last_lr()[0]
    print(f"Epoch {epoch} completed. Current learning rate: {current_lr}")

    # æ ¡éªŒé˜¶æ®µ
    print("Starting validation...")
    val_loss, val_metrics = validate_model(generator, val_loader, device, structure_loss)

    print(f"Validation Results - Loss: {val_loss:.4f}")
    print(f"  ğŸ¯ IoU: {val_metrics['iou']:.4f}")
    print(f"  F1-Score: {val_metrics['f1']:.4f}")
    print(f"  Precision: {val_metrics['precision']:.4f}")
    print(f"  Recall: {val_metrics['recall']:.4f}")
    print(f"  Accuracy: {val_metrics['accuracy']:.4f}")

    # æ£€æŸ¥æ˜¯å¦æ˜¯æœ€ä½³æ¨¡å‹ - ä½¿ç”¨IoUä½œä¸ºä¸»è¦æŒ‡æ ‡
    current_iou = val_metrics["iou"]
    current_f1 = val_metrics["f1"]
    if current_iou > best_val_iou:
        best_val_iou = current_iou
        best_epoch = epoch
        # ä¿å­˜æœ€ä½³æ¨¡å‹ - ä½¿ç”¨åŠ¨æ€æ–‡ä»¶å
        save_path = opt.save_model_path
        if not os.path.exists(save_path):
            os.makedirs(save_path)
        best_model_filename = generate_best_model_filename(model_name, opt.pretrained_weights)
        best_model_path = os.path.join(save_path, best_model_filename)
        torch.save(generator.state_dict(), best_model_path)
        print(f"ğŸ‰ New best model saved! IoU: {current_iou:.4f}, F1: {current_f1:.4f}")
        print(f"   Saved as: {best_model_filename}")

    # æ—©åœæ£€æŸ¥ - ä½¿ç”¨IoU
    early_stopping(current_iou, generator)
    if early_stopping.early_stop:
        print(f"Early stopping triggered at epoch {epoch}")
        print(f"Best IoU score: {best_val_iou:.4f} at epoch {best_epoch}")
        break

    # å®šæœŸä¿å­˜æ£€æŸ¥ç‚¹ - ä½¿ç”¨åŠ¨æ€æ–‡ä»¶å
    save_path = opt.save_model_path
    if not os.path.exists(save_path):
        os.makedirs(save_path)
    if epoch >= 0 and epoch % 10 == 0:
        checkpoint_filename = generate_checkpoint_filename(epoch, model_name, opt.pretrained_weights)
        checkpoint_path = os.path.join(save_path, checkpoint_filename)
        torch.save(generator.state_dict(), checkpoint_path)
        print(f"Checkpoint saved: {checkpoint_filename}")

# è®­ç»ƒç»“æŸåçš„æ€»ç»“
print("\n" + "=" * 50)
print("Training completed!")
print(f"Best validation IoU score: {best_val_iou:.4f} achieved at epoch {best_epoch}")
best_model_filename = generate_best_model_filename(model_name, opt.pretrained_weights)
print(f"Best model saved at: {os.path.join(opt.save_model_path, best_model_filename)}")
print("=" * 50)
